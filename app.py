import difflib
import re
from urllib.parse import quote_plus

import streamlit as st
from scraper import scrape
from rewriter import rewrite


def attach_image_links(body: str, image_urls: list[str]) -> str:
    """ë³¸ë¬¸ì˜ [ì´ë¯¸ì§€: keyword] ë˜ëŠ” [ì´ë¯¸ì§€]ë¥¼ ì›ë³¸ ì—­ì´ë¯¸ì§€ ê²€ìƒ‰ ë§í¬ + í‚¤ì›Œë“œ ê²€ìƒ‰ ë§í¬ë¡œ ë³€í™˜í•œë‹¤."""
    url_iter = iter(image_urls)

    def replace_match(m):
        full = m.group(0)
        # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ì¶œ
        kw_match = re.match(r"\[ì´ë¯¸ì§€:\s*(.+?)\]", full)
        keyword = kw_match.group(1).strip() if kw_match else ""

        # ì›ë³¸ ì´ë¯¸ì§€ URLì´ ìˆìœ¼ë©´ Google Lens ì—­ì´ë¯¸ì§€ ê²€ìƒ‰
        orig_url = next(url_iter, None)
        if orig_url:
            lens_url = f"https://lens.google.com/uploadbyurl?url={quote_plus(orig_url)}"
            result = f"[ì´ë¯¸ì§€] (ìœ ì‚¬ ì´ë¯¸ì§€ ì°¾ê¸°: {lens_url})"
        elif keyword:
            search_url = f"https://www.google.com/search?q={quote_plus(keyword)}&tbm=isch"
            result = f"[ì´ë¯¸ì§€] (ì´ë¯¸ì§€ ê²€ìƒ‰: {search_url})"
        else:
            result = "[ì´ë¯¸ì§€]"
        return result

    return re.sub(r"\[ì´ë¯¸ì§€:[^\]]*\]|\[ì´ë¯¸ì§€\]", replace_match, body)


def parse_rewrite_result(text: str) -> dict:
    """GPT ê²°ê³¼ë¥¼ [ì œëª©], [ë³¸ë¬¸], [í•´ì‹œíƒœê·¸] ì„¹ì…˜ìœ¼ë¡œ íŒŒì‹±í•œë‹¤."""
    title = ""
    body = ""
    hashtags = ""

    # ì„¹ì…˜ ë¶„ë¦¬
    sections = re.split(r"\[ì œëª©\]|\[ë³¸ë¬¸\]|\[í•´ì‹œíƒœê·¸\]", text)
    headers = re.findall(r"\[ì œëª©\]|\[ë³¸ë¬¸\]|\[í•´ì‹œíƒœê·¸\]", text)

    mapping = {}
    for i, header in enumerate(headers):
        mapping[header] = sections[i + 1].strip() if i + 1 < len(sections) else ""

    title = mapping.get("[ì œëª©]", "")
    body = mapping.get("[ë³¸ë¬¸]", "")
    hashtags = mapping.get("[í•´ì‹œíƒœê·¸]", "")

    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ë¥¼ ë³¸ë¬¸ìœ¼ë¡œ
    if not body:
        body = text
    return {"title": title, "body": body, "hashtags": hashtags}

st.set_page_config(page_title="ë¸”ë¡œê·¸ ì¬ì‘ì„± for ì„¸í¬", page_icon="âœï¸", layout="wide")

# â”€â”€ ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ â”€â”€
if not st.session_state.get("authenticated"):
    st.title("ğŸ”’ ë¡œê·¸ì¸")
    pw = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if st.button("í™•ì¸", type="primary"):
        if pw == st.secrets["PASSWORD"]:
            st.session_state["authenticated"] = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    st.stop()

# â”€â”€ ë©”ì¸ â”€â”€
st.title("âœï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì¬ì‘ì„± for ì„¸í¬")

# URL ì…ë ¥ ì¹¸ ê´€ë¦¬
if "url_count" not in st.session_state:
    st.session_state["url_count"] = 3

url_count = st.session_state["url_count"]
valid_urls = []

st.markdown(f"**URL ëª©ë¡ ({'{'}0{'}'})** ğŸ‘‡".replace("{0}", "0"))
url_placeholder = st.empty()

with url_placeholder.container():
    for idx in range(url_count):
        val = st.text_input(
            f"URL {idx + 1}",
            placeholder="https://blog.naver.com/blogid/123456789",
            key=f"url_input_{idx}",
            label_visibility="collapsed",
        )
        if val and val.strip():
            valid_urls.append(val.strip())

    col_add, col_count = st.columns([1, 3])
    if col_add.button("â• URL ì¶”ê°€", key="add_url"):
        st.session_state["url_count"] += 1
        st.rerun()
    col_count.markdown(f"ì…ë ¥ëœ URL: **{len(valid_urls)}**ê°œ")

if st.button("ì¬ì‘ì„±í•˜ê¸°", type="primary", use_container_width=True):
    urls = valid_urls
    if not urls:
        st.error("ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    api_key = st.secrets["OPENAI_API_KEY"]
    results = []
    progress = st.progress(0, text="ì‹œì‘í•˜ëŠ” ì¤‘...")

    for i, url in enumerate(urls):
        progress.progress(i / len(urls), text=f"{i + 1}/{len(urls)} ì²˜ë¦¬ ì¤‘...")

        # 1) í¬ë¡¤ë§
        try:
            data = scrape(url)
        except Exception as e:
            results.append({"url": url, "error": f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}"})
            continue

        # 2) ì¬ì‘ì„±
        try:
            rewritten = rewrite(data["title"], data["content"], api_key)
        except Exception as e:
            results.append({"url": url, "error": f"ì¬ì‘ì„± ì‹¤íŒ¨: {e}"})
            continue

        # 3) íŒŒì‹± & ì´ë¯¸ì§€ ê²€ìƒ‰ & í†µê³„
        parsed = parse_rewrite_result(rewritten)
        original_text = data["content"]
        image_count = original_text.count("[ì´ë¯¸ì§€")
        body = parsed["body"]

        # ìˆœìˆ˜ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚° (ì´ë¯¸ì§€ íƒœê·¸, í‚¤ì›Œë“œ ì œê±°)
        pure_body = re.sub(r"\[ì´ë¯¸ì§€:[^\]]*\]|\[ì´ë¯¸ì§€\]", "", body).strip()
        rewritten_len = len(pure_body)

        # ì´ë¯¸ì§€ ê²€ìƒ‰ ë§í¬ ìƒì„± (ì›ë³¸ ì´ë¯¸ì§€ URLë¡œ ì—­ì´ë¯¸ì§€ ê²€ìƒ‰)
        body = attach_image_links(body, data.get("image_urls", []))

        similarity = difflib.SequenceMatcher(None, original_text, pure_body).ratio()

        results.append({
            "url": url,
            "title": data["title"],
            "original": original_text,
            "original_len": len(original_text),
            "image_count": image_count,
            "new_title": parsed["title"],
            "body": body,
            "hashtags": parsed["hashtags"],
            "rewritten_len": rewritten_len,
            "similarity": similarity,
        })

    progress.progress(1.0, text="ì™„ë£Œ!")

    # â”€â”€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ â”€â”€
    st.markdown("---")
    st.subheader("ê²°ê³¼")

    for i, r in enumerate(results, 1):
        if "error" in r:
            st.error(f"**{i}.** {r['url']}\n\n{r['error']}")
            continue

        # ìš”ì•½ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ì›ë¬¸ ê¸¸ì´", f"{r['original_len']:,}ì")
        col2.metric("ì´ë¯¸ì§€", f"{r['image_count']}ì¥")
        col3.metric("ì¬ì‘ì„± ê¸¸ì´", f"{r['rewritten_len']:,}ì")
        col4.metric("ìœ ì‚¬ìœ¨", f"{r['similarity']:.0%}")

        # ì›ë¬¸ & ì¬ì‘ì„± ê²°ê³¼ (ì ‘í˜€ìˆìŒ)
        with st.expander(f"**{i}. {r['title']}**", expanded=False):
            tab_rewrite, tab_original = st.tabs(["ì¬ì‘ì„± ê²°ê³¼", "ì›ë¬¸"])
            with tab_rewrite:
                if r["new_title"]:
                    st.markdown(f"**ì¶”ì²œ ì œëª©**")
                    st.code(r["new_title"], language=None)
                st.markdown(f"**ë³¸ë¬¸**")
                # ## ì†Œì œëª©ì„ ë³¼ë“œë¡œ, ì´ë¯¸ì§€ ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
                display_body = re.sub(
                    r"^## (.+)$",
                    r"**\1**",
                    r["body"],
                    flags=re.MULTILINE,
                )
                display_body = re.sub(
                    r"\(ìœ ì‚¬ ì´ë¯¸ì§€ ì°¾ê¸°: (https://[^\)]+)\)",
                    r"([ìœ ì‚¬ ì´ë¯¸ì§€ ì°¾ê¸° â†’](\1))",
                    display_body,
                )
                display_body = re.sub(
                    r"\(ì´ë¯¸ì§€ ê²€ìƒ‰: (https://[^\)]+)\)",
                    r"([ì´ë¯¸ì§€ ê²€ìƒ‰ â†’](\1))",
                    display_body,
                )
                st.markdown(display_body)

                # ë³µì‚¬ìš© í…ìŠ¤íŠ¸: ì´ë¯¸ì§€ ë§í¬ë¥¼ [ì´ë¯¸ì§€1], [ì´ë¯¸ì§€2]... ë¡œ ë³€í™˜
                img_counter = [0]
                def _number_images(m):
                    img_counter[0] += 1
                    return f"[ì´ë¯¸ì§€{img_counter[0]}]"
                copy_text = re.sub(
                    r"\[ì´ë¯¸ì§€\] \(ìœ ì‚¬ ì´ë¯¸ì§€ ì°¾ê¸°: [^\)]+\)|\[ì´ë¯¸ì§€\] \(ì´ë¯¸ì§€ ê²€ìƒ‰: [^\)]+\)|\[ì´ë¯¸ì§€\]",
                    _number_images,
                    r["body"],
                )

                # ì „ì²´ ë³µì‚¬ í…ìŠ¤íŠ¸ (ì œëª© + ë³¸ë¬¸ + í•´ì‹œíƒœê·¸)
                full_copy = ""
                if r["new_title"]:
                    full_copy += r["new_title"] + "\n\n"
                full_copy += copy_text
                if r["hashtags"]:
                    full_copy += "\n\n" + r["hashtags"]

                import json
                escaped = json.dumps(full_copy)
                st.components.v1.html(f"""
                <div style="display:flex;align-items:center;gap:8px;margin-bottom:4px;">
                    <span style="font-weight:700;font-size:14px;">ë³µì‚¬ìš© í…ìŠ¤íŠ¸</span>
                    <button onclick="copyText(this)" style="
                        padding:4px 12px;font-size:13px;cursor:pointer;
                        border:1px solid #ccc;border-radius:6px;background:#fff;
                    ">ğŸ“‹ ë³µì‚¬í•˜ê¸°</button>
                </div>
                <script>
                function copyText(btn) {{
                    navigator.clipboard.writeText({escaped}).then(function() {{
                        btn.textContent = 'âœ… ë³µì‚¬ ì™„ë£Œ!';
                        btn.style.background = '#e6ffe6';
                        setTimeout(function() {{
                            btn.textContent = 'ğŸ“‹ ë³µì‚¬í•˜ê¸°';
                            btn.style.background = '#fff';
                        }}, 2000);
                    }});
                }}
                </script>
                """, height=40)

                import hashlib
                content_hash = hashlib.md5(full_copy.encode()).hexdigest()[:8]
                st.text_area(
                    "copy",
                    value=full_copy,
                    height=300,
                    label_visibility="collapsed",
                    key=f"copy_{i}_{content_hash}",
                )

                if r["hashtags"]:
                    st.markdown(f"**í•´ì‹œíƒœê·¸**")
                    st.code(r["hashtags"], language=None)
            with tab_original:
                st.text(r["original"])

    st.balloons()
